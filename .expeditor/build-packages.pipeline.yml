expeditor:
  secrets:
    PIPELINE_HAB_AUTH_TOKEN:
      path: account/static/habitat/chef-ci
      field: auth_token # Production Builder
      # acceptance_auth_token = acceptance
  accounts:
    - aws/chef-cd
  defaults:
    buildkite:
      timeout_in_minutes: 45
      env:
        HAB_ORIGIN: "chef"
        PIPELINE_HAB_BLDR_URL: "https://bldr.habitat.sh"
        # Necessary to prevent old studios from poisoning builds after core plans refreshes
        HAB_STUDIO_SECRET_HAB_PREFER_LOCAL_CHEF_DEPS: "true"
        HAB_STUDIO_SECRET_HAB_REFRESH_CHANNEL: "unstable"

steps:

  - label: "[:linux: build hab-pkg-export-tar and upload to :amazon-s3:]"
    command:
      - echo "--- testing hab export tar chef/chef-infra-client"
      - hab pkg export tar chef/chef-infra-client --channel unstable
      # - tar_name=$(find . -regex "./chef-chef-infra-client-[0-9]+\.[0-9]+\.[0-9]+-[0-9]+\.tar\.gz" -type f -exec basename {} \;) # tar name. pass this to next steps?
      - find . -regex "./chef-chef-infra-client-[0-9]+\.[0-9]+\.[0-9]+-[0-9]+\.tar\.gz" -type f -exec basename {} \;
      - mkdir -p upload && find . -name "chef-chef-infra-client-*.tar.gz" | grep -E 'chef-chef-infra-client-[0-9]+\.[0-9]+\.[0-9]+-[0-9]+\.tar\.gz' | xargs -I {} cp {} upload/
      # - mkdir -p upload && cp $file_path upload/
      - cd upload/ && buildkite-agent artifact upload "*.tar.gz" && aws s3 cp chef-chef-infra-client-19.0.82-20250128214643.tar.gz s3://rc2-hab-pkg-chef-client/rc2_tar/chef-chef-infra-client-19.0.82-20250128214643.tar.gz
      # - export HAB_PACKAGE_TAR_FILENAME=$(find . -regex "./chef-chef-infra-client-[0-9]+\.[0-9]+\.[0-9]+-[0-9]+\.tar\.gz" -type f -exec basename {} \;)
      #- set HAB_PACKAGE_TAR_FILENAME=$(find . -regex "./chef-chef-infra-client-[0-9]+\.[0-9]+\.[0-9]+-[0-9]+\.tar\.gz" -type f -exec basename {} \;)
      - export HAB_PACKAGE_TAR_FILENAME=$(find . -name "chef-chef-infra-client*.tar.gz" -type f -exec basename {} \;)
      - echo "hab pkg tar name - $HAB_PACKAGE_TAR_FILENAME"
      # - cd upload/ && buildkite-agent artifact upload "*.tar.gz" && aws s3 sync . s3://rc2-hab-pkg-chef-client/rc2_tar/ --exclude "*" --include "*.tar.gz" --region us-west-2 --profile chef-cd

    expeditor:
      executor:
        docker:
          privileged: true
          environment:
            - BUILD_PKG_TARGET=x86_64-linux

  - wait

  - label: ":linux: Build RPM package"
    commands:
      # - pkg_identifier=$(sed 's/\//-/g' <<< $EXPEDITOR_PKG_IDENTS_CHEFINFRACLIENTX86_64LINUX).tar.gz
      - export CHEF_INFRA_MIGRATE_TAR=s3://rc2-hab-pkg-chef-client/rc2_migration_tool/migration-tools_Linux_x86_64.tar.gz
      - export CHEF_INFRA_HAB_TAR=s3://rc2-hab-pkg-chef-client/rc2_tar/$HAB_PACKAGE_TAR_FILENAME
      - echo $CHEF_INFRA_HAB_TAR
      - ./.expeditor/scripts/build-infra-rpm.sh
      - pkg_name=$(cat RPM_PKG_NAME)
      - buildkite-agent artifact upload $pkg_name
      - aws s3 cp $pkg_name s3://chef-hab-migration-tool-bucket/rc2_hab_pkg_chef_client/rc2_installer_folder/$pkg_name
    expeditor:
      executor:
        linux:
          privileged: true

  - label: ":linux: Build Debian package"
    agents:
      queue: omnibus-ubuntu-18.04-aarch64
    commands:
      # - pkg_identifier=$(sed 's/\//-/g' <<< $EXPEDITOR_PKG_IDENTS_CHEFINFRACLIENTX86_64LINUX).tar.gz
      - export CHEF_INFRA_MIGRATE_TAR=s3://rc2-hab-pkg-chef-client/rc2_migration_tool/migration-tools_Linux_x86_64.tar.gz
      - export CHEF_INFRA_HAB_TAR=s3://rc2-hab-pkg-chef-client/rc2_tar/"$HAB_PACKAGE_TAR_FILENAME"
      - echo $CHEF_INFRA_HAB_TAR
      - ./.expeditor/scripts/build-infra-deb.sh
      - pkg_name=$(cat DEB_PKG_NAME)
      - buildkite-agent artifact upload $pkg_name
      - aws s3 cp $pkg_name s3://chef-hab-migration-tool-bucket/rc2_hab_pkg_chef_client/rc2_installer_folder/$pkg_name
    expeditor:
      executor:
        linux:
          privileged: true
